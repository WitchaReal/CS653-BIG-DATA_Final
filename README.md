## üß© ‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà 1: Upload + Glue Crawler + Athena
## ‚úÖ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: Upload customers.csv ‡πÑ‡∏õ‡∏¢‡∏±‡∏á S3

1. ‡πÄ‡∏Ç‡πâ‡∏≤ AWS Console ‚Üí S3 ‚Üí \[Create bucket]

2. ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠ bucket:

   ```
   student6196-YYYY-customers
   ```

3. ‡πÄ‡∏õ‡∏¥‡∏î bucket ‚Üí ‡∏Å‡∏î \[Create folder] ‚Üí ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠: `csv`

4. ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå `csv` ‚Üí ‡∏Å‡∏î \[Upload] ‚Üí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå `customers.csv` ‚Üí ‡∏Å‡∏î \[Upload]

---

## ‚úÖ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏™‡∏£‡πâ‡∏≤‡∏á Glue Database

1. ‡πÄ‡∏õ‡∏¥‡∏î AWS Console ‚Üí Glue ‚Üí ‡∏Å‡∏î‡πÄ‡∏°‡∏ô‡∏π `Databases` (‡πÉ‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ Data Catalog)
2. ‡∏Å‡∏î \[Add database] ‚Üí ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡πà‡∏≤:

   ```
   customers_6196_YYYY
   ```

   (‡πÄ‡∏ä‡πà‡∏ô customers\_6196\_1234) ‚Üí \[Create database]

---

## ‚úÖ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏™‡∏£‡πâ‡∏≤‡∏á Glue Crawler

1. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà Glue ‚Üí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å `Crawlers` ‚Üí \[Create crawler]

2. ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠:

   ```
   crawler-customers-6196-YYYY
   ```

3. Data source:

   * Data store: S3
   * Include path: `s3://student6196-YYYY-customers/csv/`

4. IAM role: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å `LabRole` ‡∏´‡∏£‡∏∑‡∏≠ role ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥

5. Output:

   * Database: `customers_6196_YYYY`
   * Table prefix: `customers_` (‡πÉ‡∏™‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏™‡πà‡∏Å‡πá‡πÑ‡∏î‡πâ)

6. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏£‡πá‡∏à ‚Üí ‡∏Å‡∏î Run ‚Üí ‡∏£‡∏≠‡∏à‡∏ô Crawler ‡πÄ‡∏õ‡πá‡∏ô ‚Äú**Ready**‚Äù

---

## ‚úÖ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 4: ‡πÉ‡∏ä‡πâ Athena Query ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

1. ‡πÄ‡∏õ‡∏¥‡∏î Athena ‚Üí ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Region ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö S3 ‡πÅ‡∏•‡∏∞ Glue

2. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Query results location (‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô):

   * ‡∏Å‡∏î Settings ‚Üí Manage ‚Üí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å S3 ‡πÄ‡∏ä‡πà‡∏ô:

     ```
     s3://student6196-YYYY-customers/athena-results/
     ```

3. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Database: `customers_6196_YYYY` (‡πÄ‡∏°‡∏ô‡∏π‡∏ã‡πâ‡∏≤‡∏¢)

4. ‡∏Ñ‡∏•‡∏¥‡∏Å \[New Query] ‚Üí ‡∏û‡∏¥‡∏°‡∏û‡πå SQL ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ:

```sql
SELECT * 
FROM customers.csv
WHERE country = 'Thailand';
```

> ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô `customers_xxxx_yyyy` ‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏ä‡πà‡∏ô `customers_6196_1234`

5. ‡∏Å‡∏î \[Run] ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏≠‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå

---

## ‚úÖ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 5: Capture ‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠

üì∏ ‡∏†‡∏≤‡∏û‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ:

* Glue Crawler ‡∏ó‡∏µ‡πà‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÄ‡∏õ‡πá‡∏ô ‚Äú**Ready**‚Äù
* ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å Athena ‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏® `Thailand`

----
=
=
=
=
=
=
----


## üß© ‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà 2: ‡∏™‡∏£‡πâ‡∏≤‡∏á Table ‡∏î‡πâ‡∏ß‡∏¢ SQL ‡πÅ‡∏•‡∏∞ Query ‡∏´‡∏≤‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏°‡πÉ‡∏ô‡∏õ‡∏µ 2023
## ‚úÖ Step 1: ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î `products.csv` ‡πÑ‡∏õ‡∏¢‡∏±‡∏á S3

1. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà AWS Console ‚Üí ‡πÄ‡∏Ç‡πâ‡∏≤‡πÄ‡∏°‡∏ô‡∏π S3
2. ‡∏Å‡∏î \[Create bucket] ‚Üí ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏ä‡πà‡∏ô:

```
student6196-YYYY-products
```

> ‡πÄ‡∏ä‡πà‡∏ô `student6196-yyyy-products`

3. ‡πÄ‡∏õ‡∏¥‡∏î bucket ‚Üí \[Create folder] ‚Üí ‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡πà‡∏≤: `csv`

4. ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå `csv` ‚Üí ‡∏Å‡∏î \[Upload] ‚Üí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå `products.csv` ‚Üí \[Upload] ‡∏£‡∏≠‡∏à‡∏ô 100%

---

## ‚úÖ Step 2: ‡∏™‡∏£‡πâ‡∏≤‡∏á Glue Database

1. ‡πÄ‡∏Ç‡πâ‡∏≤ AWS Console ‚Üí ‡πÑ‡∏õ‡∏ó‡∏µ‡πà Glue
2. ‡πÄ‡∏°‡∏ô‡∏π‡∏ã‡πâ‡∏≤‡∏¢ ‚Üí ‡∏Å‡∏î `Databases` ‚Üí \[Add database]
3. ‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡πà‡∏≤:

```
products_6196_YYYY
```

> ‡πÄ‡∏ä‡πà‡∏ô `products_6196_1234`

4. ‡∏Å‡∏î \[Create database]

---

## ‚úÖ Step 3: ‡πÉ‡∏ä‡πâ Athena ‡∏™‡∏£‡πâ‡∏≤‡∏á Table ‡∏î‡πâ‡∏ß‡∏¢ SQL

1. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà AWS Athena ‚Üí ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Region ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö S3/Glue

2. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Query Result Location (‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡∏ï‡∏±‡πâ‡∏á)

   * ‡∏Å‡∏î Settings ‚Üí Manage ‚Üí ‡πÉ‡∏™‡πà S3 ‡πÄ‡∏ä‡πà‡∏ô:

     ```
     s3://student6196-YYYY-products/athena-results/
     ```

3. ‡πÄ‡∏°‡∏ô‡∏π‡∏ã‡πâ‡∏≤‡∏¢: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Database ‚Üí `products_6196_YYYY`

4. ‡∏Å‡∏î \[+ New Query] ‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏ä‡πâ SQL ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠ **‡∏™‡∏£‡πâ‡∏≤‡∏á Table**

### üìÑ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á SQL ‡∏™‡∏£‡πâ‡∏≤‡∏á Table:

```sql
CREATE EXTERNAL TABLE IF NOT EXISTS products_6196_yyyy_products (
  user_id STRING,
  product_id STRING,
  category STRING,
  signup_date STRING
)
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
WITH SERDEPROPERTIES (
  'separatorChar' = ',',
  'quoteChar' = '\"'
)
LOCATION 's3://student6196-yyyy-products/csv/'
TBLPROPERTIES ('has_encrypted_data'='false');
```

> ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô:
> * `LOCATION` ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö path ‡∏Ç‡∏≠‡∏á S3

5. ‡∏Å‡∏î \[Run] ‚Üí ‡∏ñ‡πâ‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏à‡∏∞‡πÇ‡∏ú‡∏•‡πà‡∏ó‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏ã‡πâ‡∏≤‡∏¢

---

## ‚úÖ Step 4: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Table

‡∏£‡∏±‡∏ô SQL ‡∏ï‡∏£‡∏ß‡∏à‡∏î‡∏π‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:

```sql
SELECT * FROM products_6196_yyyy_products
LIMIT 10;
```

> ‡πÄ‡∏ä‡πá‡∏Ñ‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤ `event_time` ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏µ 2023 ‡∏≠‡∏¢‡∏π‡πà

---

## ‚úÖ Step 5: Query ‡∏´‡∏≤ Top 1 category ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ô‡∏™‡∏ô‡πÉ‡∏à‡∏°‡∏≤‡∏Å‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏õ‡∏µ 2023

```sql
SELECT category, COUNT(*) AS interested_count
FROM products_6196_yyyy_products
WHERE regexp_like(signup_date, '.*2023$')
# event_time LIKE '2023%'
GROUP BY category
ORDER BY interested_count DESC
LIMIT 1;
```

---

## ‚úÖ Step 6: Capture ‡∏†‡∏≤‡∏û‡∏™‡πà‡∏á

üì∏ **Capture 1 ‡∏†‡∏≤‡∏û ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏´‡πá‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ô‡∏µ‡πâ**:

1. SQL ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á Table (Query ‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô)
2. Preview ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Table (`SELECT *`)
3. ‡∏ú‡∏•‡∏Ç‡∏≠‡∏á Query ‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á category ‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏°‡∏õ‡∏µ 2023
----
=
=
=
=
=
=
----

## üß© ‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà 3: ‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡∏´‡πâ‡∏≠‡∏á‡πÄ‡∏¢‡πá‡∏ô‡∏î‡πâ‡∏ß‡∏¢ IoT + Lambda + DynamoDB + SNS

---
### ‚úÖ Step 1: ‡∏™‡∏£‡πâ‡∏≤‡∏á DynamoDB Table

1. ‡πÄ‡∏Ç‡πâ‡∏≤ AWS Console ‚Üí ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ "DynamoDB"
2. ‡∏Å‡∏î \[Create Table]
3. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:

   * Table name: `iot-temperature-data-6196-YYYY`
   * Partition key: `roomId` (String)
   * Sort key: `timestamp` (String) *(‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÑ‡∏î‡πâ‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡πÄ‡∏ß‡∏•‡∏≤)*

‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥

---

### ‚úÖ Step 2: ‡∏™‡∏£‡πâ‡∏≤‡∏á SNS Topic ‡πÅ‡∏•‡∏∞ Subscribe Email

1. ‡πÄ‡∏Ç‡πâ‡∏≤ AWS Console ‚Üí ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ "SNS"

2. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà Topics ‚Üí ‡∏Å‡∏î \[Create topic]

3. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤:

   * Type: Standard
   * Name: `temperature-alerts-6196-YYYY`

4. ‡πÄ‡∏õ‡∏¥‡∏î Topic ‚Üí ‡∏Å‡∏î \[Create subscription]

   * Protocol: Email
   * Endpoint: ‡πÉ‡∏™‡πà‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á ‚Üí ‡∏Å‡∏î \[Create subscription]

5. ‡πÑ‡∏õ‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö (‡∏Å‡∏î "Confirm subscription")

---

### ‚úÖ Step 3: ‡∏™‡∏£‡πâ‡∏≤‡∏á Lambda Function

1. ‡πÄ‡∏Ç‡πâ‡∏≤ AWS Console ‚Üí Lambda ‚Üí \[Create function]
2. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å:

   * Name: `iot-temperature-6196-YYYY-logs`
   * Runtime: Python 3.9
   * Permissions: ‡πÉ‡∏ä‡πâ `LabRole` ‡∏´‡∏£‡∏∑‡∏≠ role ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô DynamoDB ‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á SNS

---

### ‚úÖ ‡πÇ‡∏Ñ‡πâ‡∏î Python ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Lambda:

```python
import json
import boto3
from decimal import Decimal

dynamodb = boto3.resource('dynamodb')
sns = boto3.client('sns')

# ‡πÉ‡∏™‡πà‡∏ä‡∏∑‡πà‡∏≠ Table ‡πÅ‡∏•‡∏∞ SNS ARN ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
table_name = 'iot-temperature-data-6196-YYYY'
sns_topic_arn = 'arn:aws:sns:region:account-id:temperature-alerts-XXXX-YYYY'

table = dynamodb.Table(table_name)

def lambda_handler(event, context):
    for record in event['records']:
        payload = json.loads(record['value'])

        room_id = payload['roomId']
        timestamp = payload['timestamp']
        temperature = Decimal(str(payload['temperature']))

        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á DynamoDB
        table.put_item(
            Item={
                'roomId': room_id,
                'timestamp': timestamp,
                'temperature': temperature
            }
        )

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡πà‡∏ß‡∏á‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥
        if temperature < 2 or temperature > 8:
            message = f"Alert: Room {room_id} temperature is {temperature}¬∞C at {timestamp}."
            sns.publish(
                TopicArn=sns_topic_arn,
                Message=message,
                Subject="Cold Room Temperature Alert"
            )

    return {
        'statusCode': 200,
        'body': json.dumps('Processed successfully')
    }
```

> üìå **‡∏≠‡∏¢‡πà‡∏≤‡∏•‡∏∑‡∏°‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô:**
>
> * `table_name`
> * `sns_topic_arn` ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏≠‡∏á

---

### ‚úÖ Step 4: ‡∏™‡∏£‡πâ‡∏≤‡∏á IoT Rule

1. ‡πÄ‡∏Ç‡πâ‡∏≤ AWS Console ‚Üí AWS IoT Core ‚Üí Message Routing ‚Üí \[Create rule]

2. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î:

   * Name: `IoTRule_coldroom6196_YYYY`
   * SQL statement:

     ```sql
     SELECT * FROM 'coldroom6196-YYYY/temperature'
     ```
   * SQL version: 2016-03-23

3. Add Action ‚Üí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å: **Invoke Lambda function**

   * ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å `iot-temperature-6196-YYYY-logs`
   * Allow permissions

---

### ‚úÖ Step 5: ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡πà‡∏á MQTT Messages

1. ‡πÄ‡∏Ç‡πâ‡∏≤ AWS IoT Core ‚Üí MQTT Test Client
2. ‡∏Å‡∏î "Publish to a topic"

#### üìå Topic:

```
coldroom6196-YYYY/temperature
```

#### üìå ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Payload (‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á):

```json
{
  "roomId": "R001",
  "timestamp": "2025-05-21T10:15:00Z",
  "temperature": 5.5
}
```

#### üìå ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Payload (‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥):

```json
{
  "roomId": "R002",
  "timestamp": "2025-05-21T10:20:00Z",
  "temperature": 10.2
}
```

> ‚ú≥Ô∏è ‡∏™‡πà‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î **10 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á**:
>
> * 3 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á: ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á 2‚Äì8¬∞C
> * 7 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á: ‡∏ô‡∏≠‡∏Å‡∏ä‡πà‡∏ß‡∏á

---
### ‚úÖ Step 6: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå

* **DynamoDB**: ‡πÄ‡∏Ç‡πâ‡∏≤ Table ‚Üí ‡∏î‡∏π Items ‚Üí ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏´‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
* **SNS (Email)**: ‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡∏ô‡∏≠‡∏Å‡∏ä‡πà‡∏ß‡∏á
---
### ‚úÖ Step 7: Capture ‡∏†‡∏≤‡∏û‡πÄ‡∏î‡∏µ‡∏¢‡∏ß

üì∏ ‡∏†‡∏≤‡∏û Capture ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡πà‡∏á:

* IoT Rule + SQL Statement + Lambda ‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠
* ‡πÇ‡∏Ñ‡πâ‡∏î Lambda ‡∏ö‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠
* DynamoDB ‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
* ‡∏†‡∏≤‡∏û‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô (‡∏à‡∏≤‡∏Å SNS)
----
=
=
=
=
=
=
----

## üß© ‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà 4: ‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡πà‡∏á‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡πÅ‡∏ö‡∏ö‡∏™‡∏∏‡πà‡∏°‡∏ú‡πà‡∏≤‡∏ô Cloud9 ‚Üí Firehose ‚Üí S3

---

### ‚úÖ Step 1: ‡∏™‡∏£‡πâ‡∏≤‡∏á S3 Bucket ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

1. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà AWS Console ‚Üí S3 ‚Üí ‡∏Å‡∏î \[Create bucket]

2. ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠ Bucket ‡πÄ‡∏ä‡πà‡∏ô:

   ```
   s3-temperature-store-6196-YYYY
   ```

   (‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô `XXXX-YYYY` ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏£‡∏´‡∏±‡∏™‡∏Ç‡∏≠‡∏á‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤)

3. Region: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö Cloud9 ‡πÅ‡∏•‡∏∞ Firehose (‡πÄ‡∏ä‡πà‡∏ô `us-east-1`)

4. ‡∏Å‡∏î \[Create bucket]

---

### ‚úÖ Step 2: ‡∏™‡∏£‡πâ‡∏≤‡∏á Amazon Kinesis Data Firehose

1. AWS Console ‚Üí ‡πÑ‡∏õ‡∏ó‡∏µ‡πà **Amazon Data Firehose**
2. ‡∏Å‡∏î \[Create delivery stream]

#### ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:

* **Source**: Direct PUT or other sources

* **Destination**: Amazon S3

* **Delivery stream name**:

  ```
  temperature-stream-6196-YYYY
  ```

* **S3 Bucket**: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å `s3-temperature-store-6196-YYYY`

* **S3 prefix (optional)**: `temperature-data/`

* **Permissions**: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å `LabRole` ‡∏´‡∏£‡∏∑‡∏≠ Role ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥

3. ‡∏Å‡∏î \[Create delivery stream]

---

### ‚úÖ Step 3: ‡∏™‡∏£‡πâ‡∏≤‡∏á AWS Cloud9 Environment

1. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà AWS Console ‚Üí Cloud9 ‚Üí ‡∏Å‡∏î \[Create environment]

#### ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤:

* Name: `feed_temperature6196_YYYY`
* Instance type: `t2.micro`
* Platform: `Amazon Linux 2`
* Cost-saving: ‡∏Ñ‡πà‡∏≤ default ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢
* Permissions: ‡πÉ‡∏ä‡πâ Role ‡πÄ‡∏î‡∏¥‡∏° (LabRole)

2. ‡∏Å‡∏î \[Create environment]

---

### ‚úÖ Step 4: ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô Python Script ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡πà‡∏á‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥ ‚Üí Firehose

#### üîß ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Boto3 (‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ):

‡πÄ‡∏õ‡∏¥‡∏î Terminal:

```bash
pip install boto3
```

#### ‚úèÔ∏è ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà‡∏ä‡∏∑‡πà‡∏≠ `send_temperature.py` ‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏™‡πà‡πÇ‡∏Ñ‡πâ‡∏î‡∏ô‡∏µ‡πâ:

```python
import boto3
import json
import time
import random
from datetime import datetime

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏∑‡πà‡∏≠ Firehose stream ‡πÅ‡∏•‡∏∞ region
delivery_stream_name = 'temperature-stream-6196-YYYY'
region_name = 'us-east-1'  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö Region ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì

client = boto3.client('firehose', region_name=region_name)

def generate_temperature_data():
    return {
        "roomId": f"R{random.randint(1, 5):03d}",
        "timestamp": datetime.utcnow().isoformat(),
        "temperature": round(random.uniform(-5, 15), 2)
    }

while True:
    data = generate_temperature_data()
    json_data = json.dumps(data)
    print("Sending:", json_data)

    response = client.put_record(
        DeliveryStreamName=delivery_stream_name,
        Record={"Data": json_data + "\n"}
    )

    print("Response:", response['ResponseMetadata']['HTTPStatusCode'])
    time.sleep(3)
```

> ‚úÖ ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô `delivery_stream_name` ‡πÅ‡∏•‡∏∞ `region_name` ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì

---

### ‚úÖ Step 5: ‡∏£‡∏±‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÉ‡∏ô Cloud9

```bash
python send_temperature.py
```

üìå Terminal ‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤:

* ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ñ‡∏π‡∏Å‡∏™‡∏∏‡πà‡∏°‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏ó‡∏∏‡∏Å 3 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
* ‡∏ö‡∏≠‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ Response: 200 (‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à)

---

### ‚úÖ Step 6: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô S3

1. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà S3 ‚Üí ‡πÄ‡∏õ‡∏¥‡∏î bucket `s3-temperature-store-6196-YYYY`
2. ‡πÄ‡∏Ç‡πâ‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå `temperature-data/` ‚Üí ‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå `.json` ‡∏´‡∏£‡∏∑‡∏≠ `.gz` (‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏µ‡∏ö‡∏≠‡∏±‡∏î‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)
3. ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå ‚Üí ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏Ñ‡∏∑‡∏≠ JSON 1 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‡πÄ‡∏ä‡πà‡∏ô:

```json
{"roomId": "R001", "timestamp": "2025-05-21T10:50:00Z", "temperature": 7.82}
```

---

## ‚úÖ Step 7: Capture ‡∏†‡∏≤‡∏û‡πÄ‡∏î‡∏µ‡∏¢‡∏ß

üì∏ ‡∏†‡∏≤‡∏û Capture ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡πà‡∏á:

* Firehose Console ‚Üí ‡πÅ‡∏™‡∏î‡∏á‡∏ä‡∏∑‡πà‡∏≠ `temperature-stream-6196XXXX-YYYY`
* Cloud9 ‚Üí ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå `send_temperature.py` ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î
* S3 Console ‚Üí ‡πÄ‡∏õ‡∏¥‡∏î‡∏î‡∏π bucket + ‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á
----
=
=
=
=
=
=
----

## üß© ‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà 5: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Sentiment ‡∏à‡∏≤‡∏Å Feedback ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Glue + AI Model
---

### ‚úÖ Step 1: ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå `feedbacks.csv` ‡πÑ‡∏õ S3

1. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà AWS Console ‚Üí S3

2. ‡∏™‡∏£‡πâ‡∏≤‡∏á Bucket ‡∏ä‡∏∑‡πà‡∏≠:

   ```
   student6196-YYYY-ml
   ```

3. ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô Bucket ‚Üí ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ä‡∏∑‡πà‡∏≠:

   ```
   raw/
   ```

4. ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå `feedbacks.csv` ‡∏•‡∏á‡πÉ‡∏ô `raw/`

--- 

### ‚úÖ Step 2: Glue Job  ‡πÅ‡∏õ‡∏•‡∏á CSV ‚Üí JSON

1. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà AWS Glue Studio ‚Üí Create job ‚Üí *Visual with a source and target*

2. ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠: `csv-to-json-job`

3. Source: Amazon S3 ‚Üí Browse ‡πÑ‡∏õ‡∏ó‡∏µ‡πà:

   ```
   s3://student6196-YYYY-ml/raw/feedbacks.csv
   ```

4. Format: CSV ‚Üí Set header = true

5. Target: Amazon S3 ‚Üí Location:

   ```
   s3://student6196-YYYY-ml/preprocessed/
   ```

6. Format: JSON

7. ‡∏Å‡∏î **Run Job**

8. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå JSON ‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏ô `preprocessed/`

---

### ‚úÖ Step 3: Deploy Sentiment API ‡∏î‡πâ‡∏ß‡∏¢ CloudFormation

1. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà AWS Console ‚Üí CloudFormation
2. \[Create Stack] ‚Üí With new resources
3. Upload ‡πÑ‡∏ü‡∏•‡πå `sentiment-api.yaml`
4. Stack name: `sentiment-analysis-stack`
5. ‡∏Å‡∏î Next ‚Üí Next ‚Üí Create stack

üìå ‡∏£‡∏≠‡∏à‡∏ô `Status = CREATE_COMPLETE`

6. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡πá‡∏ö **Outputs** ‚Üí ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤ `SentimentEndpoint` (URL ‡πÄ‡∏ä‡πà‡∏ô: `http://ec2-xx-xx-xx-xx.compute-1.amazonaws.com/predict`)

---

### ‚úÖ Step 4: ‡∏ó‡∏î‡∏™‡∏≠‡∏ö API ‡∏î‡πâ‡∏ß‡∏¢ Web Browser

‡πÄ‡∏õ‡∏¥‡∏î Browser ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏Ç‡πâ‡∏≤:

```
http://ec2-xx-xx-xx-xx.compute-1.amazonaws.com/predict
```

‡∏´‡∏≤‡∏Å‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ‚Üí ‡∏à‡∏∞‡∏Ç‡∏∂‡πâ‡∏ô:

```json
{"detail":"Method Not Allowed"}
```

üì∏ *Capture ‡∏†‡∏≤‡∏û‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ‡πÑ‡∏ß‡πâ‡∏î‡πâ‡∏ß‡∏¢*

---

### ‚úÖ Step 5: Glue Python Shell Job ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Sentiment

1. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà AWS Glue ‚Üí Jobs ‚Üí \[Create job]
2. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å: *Author script with Python Shell*
3. ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠: `sentiment-analysis-job`
4. IAM Role: LabRole
5. Python version: 3.9

---

### üß† ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î Glue Python Shell:

```python
import json
import boto3
import requests

s3 = boto3.client('s3')

# ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô `input_bucket`, `endpoint`, `input_key`, ‡πÅ‡∏•‡∏∞ `output_key` ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
input_bucket = 'student6196-YYYY-ml'
input_key = 'preprocessed/feedbacks.json'
output_key = 'processed/sentiment_results.json'
endpoint = 'http://ec2-xx-xx-xx-xx.compute-1.amazonaws.com/predict'

# ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• feedback ‡∏à‡∏≤‡∏Å S3
obj = s3.get_object(Bucket=input_bucket, Key=input_key)
feedbacks = json.loads(obj['Body'].read())

results = []

for feedback in feedbacks:
    text = feedback['text']
    res = requests.post(endpoint, json={'text': text})
    sentiment_data = res.json()
    
    results.append({
        'id': feedback['id'],
        'text': text,
        'sentiment': sentiment_data['sentiment'],
        'scores': sentiment_data['scores']
    })

# ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏•‡∏á S3
s3.put_object(
    Body=json.dumps(results, indent=2),
    Bucket=input_bucket,
    Key=output_key
)
```

> ‚ú¥Ô∏è ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô `input_bucket`, `endpoint`, `input_key`, ‡πÅ‡∏•‡∏∞ `output_key` ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì

---

### ‚úÖ Step 6: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÉ‡∏ô S3 ‚Üí `processed/sentiment_results.json`

‡πÄ‡∏õ‡∏¥‡∏î‡∏î‡∏π‡∏ß‡πà‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞ feedback ‡∏ñ‡∏π‡∏Å‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ:

```json
{
  "id": 3,
  "text": "I absolutely love this product!",
  "sentiment": "POSITIVE",
  "scores": {
    "positive": 0.95,
    "negative": 0.02,
    "neutral": 0.03
  }
}
```

---

### ‚úÖ Step 7: ‡πÉ‡∏ä‡πâ Athena Query ‡∏™‡∏£‡∏∏‡∏õ Sentiment

#### üìå ‡∏™‡∏£‡πâ‡∏≤‡∏á Table:

```sql
CREATE EXTERNAL TABLE sentiment_results (
  id INT,
  text STRING,
  sentiment STRING,
  scores STRUCT<positive: DOUBLE, negative: DOUBLE, neutral: DOUBLE, mixed: DOUBLE>
)
ROW FORMAT SERDE 'org.openx.data.jsonserde.JsonSerDe'
LOCATION 's3://studentXXXX-YYYY-ml/processed/';
```

#### üìå Query ‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠‡∏ö‡πà‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î:

```sql
SELECT sentiment, COUNT(*) AS count
FROM sentiment_results
GROUP BY sentiment
ORDER BY count DESC
LIMIT 1;
```

---

## ‚úÖ ‡∏†‡∏≤‡∏û Capture ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡πà‡∏á

üì∏ *‡∏£‡∏ß‡∏°‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÑ‡∏ß‡πâ‡πÉ‡∏ô‡∏†‡∏≤‡∏û‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏´‡∏£‡∏∑‡∏≠ collage*

1. ‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠ Glue Job ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô pipeline ‡∏´‡∏£‡∏∑‡∏≠ script ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
2. ‡∏´‡∏ô‡πâ‡∏≤ browser ‡πÅ‡∏™‡∏î‡∏á `{"detail":"Method Not Allowed"}`
3. ‡∏´‡∏ô‡πâ‡∏≤ S3 ‡∏ó‡∏µ‡πà‡∏°‡∏µ `sentiment_results.json`
4. ‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠ Athena ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏™‡∏£‡∏∏‡∏õ sentiment

----
=
=
=
=
=
=
----
## üß© ‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà 6: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢ AWS Rekognition + Glue
---

### üéØ ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡πÇ‡∏à‡∏ó‡∏¢‡πå:
1. ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û 20 ‡∏£‡∏π‡∏õ‡πÑ‡∏õ‡∏¢‡∏±‡∏á S3
2. ‡∏™‡∏£‡πâ‡∏≤‡∏á Glue Job:
   * ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå JSON ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞ S3 URI
   * ‡πÉ‡∏ä‡πâ `Rekognition` ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ (‡πÄ‡∏û‡∏® + ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à)
   * ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå JSON ‡∏•‡∏á S3
3. ‡πÉ‡∏ä‡πâ Athena:
   * ‡∏ô‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
   * ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏û‡∏®
   * ‡∏ô‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
---

### ‚úÖ Step 1: ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÑ‡∏õ‡∏¢‡∏±‡∏á S3

1. ‡∏™‡∏£‡πâ‡∏≤‡∏á S3 bucket ‡∏ä‡∏∑‡πà‡∏≠:

   ```
   student6196-YYYY-ml
   ```

2. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå `raw/`

3. ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå `1.jpg` ‡∏ñ‡∏∂‡∏á `20.jpg` ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÑ‡∏õ‡∏¢‡∏±‡∏á:

   ```
   s3://student6196-YYYY-ml/raw/
   ```

---

### ‚úÖ Step 2: Glue Job > Visual ETL > ‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πà‡∏≤‡∏á‡πÜ‡πÉ‡∏ô‡πÅ‡∏ñ‡∏ö Job Details ‡πÅ‡∏•‡∏∞‡πÉ‡∏™‡πà Code ‡πÉ‡∏ô‡πÅ‡∏ñ‡∏ö Script > run  > Python Shell Job ‡∏ó‡∏µ‡πà 1 ‚Üí ‡∏™‡∏£‡πâ‡∏≤‡∏á image\_list.json

> Job ‡∏ô‡∏µ‡πâ‡∏≠‡πà‡∏≤‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô S3 ‚Üí ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå JSON ‡∏û‡∏£‡πâ‡∏≠‡∏° S3 URI ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå

#### üîß ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î:

```python
import boto3
import json

bucket = 'student6196-YYYY-ml'
prefix = 'raw/'

s3_client = boto3.client('s3')
response = s3_client.list_objects_v2(Bucket=bucket, Prefix=prefix)

images = []
for obj in response.get('Contents', []):
    key = obj['Key']
    if key.endswith('.jpg'):
        images.append({
            'filename': key.split('/')[-1],
            's3_uri': f's3://{bucket}/{key}'
        })

output_data = {'images': images}

s3_client.put_object(
    Bucket=bucket,
    Key='preprocessed/image_list.json',
    Body=json.dumps(output_data, indent=2)
)
```

---

### ‚úÖ Step 3: Glue Python Shell Job ‡∏ó‡∏µ‡πà 2 ‚Üí ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢ Rekognition

> ‡∏≠‡πà‡∏≤‡∏ô `image_list.json` ‚Üí ‡πÉ‡∏ä‡πâ `detect_faces()` ‚Üí ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå JSON ‡∏ó‡∏µ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå

#### üîß ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î:

```python
import boto3
import json
import urllib.parse

bucket = 'student6196-YYYY-ml'
rekognition = boto3.client('rekognition')
s3 = boto3.client('s3')

# ‡∏î‡∏∂‡∏á image_list.json
obj = s3.get_object(Bucket=bucket, Key='preprocessed/image_list.json')
data = json.loads(obj['Body'].read())
images = data['images']

for image in images:
    filename = image['filename']
    s3_uri = image['s3_uri']
    s3_key = '/'.join(s3_uri.split('/', 4)[-1].split('/'))

    response = rekognition.detect_faces(
        Image={'S3Object': {'Bucket': bucket, 'Name': s3_key}},
        Attributes=['ALL']
    )

    if response['FaceDetails']:
        face = response['FaceDetails'][0]
        gender = face['Gender']['Value']
        confidence = face['Gender']['Confidence']
        has_face = True
    else:
        gender = None
        confidence = None
        has_face = False

    result = {
        'filename': filename,
        'has_face': has_face,
        'gender': gender,
        'confidence': confidence
    }

    s3.put_object(
        Bucket=bucket,
        Key=f'processed/{filename.replace(".jpg", ".json")}',
        Body=json.dumps(result, indent=2)
    )
```

---

### ‚úÖ Step 4: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå JSON ‡πÉ‡∏ô S3

1. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà S3:

   * `preprocessed/image_list.json` ‚Üí ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
   * `processed/` ‚Üí JSON 20 ‡πÑ‡∏ü‡∏•‡πå (‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏ä‡πà‡∏ô `1.json`, `2.json`, ...)

üìÑ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:

```json
{
  "filename": "7.jpg",
  "has_face": true,
  "gender": "Male",
  "confidence": 99.3
}
```

---

### ‚úÖ Step 5: ‡∏™‡∏£‡πâ‡∏≤‡∏á Table ‡πÉ‡∏ô Athena

```sql
CREATE EXTERNAL TABLE face_results (
  filename STRING,
  has_face BOOLEAN,
  gender STRING,
  confidence DOUBLE
)
ROW FORMAT SERDE 'org.openx.data.jsonserde.JsonSerDe'
LOCATION 's3://studentXXXX-YYYY-ml/processed/';
```

---

### ‚úÖ Step 6: Athena Queries

#### üîπ ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤

```sql
SELECT COUNT(*) AS face_detected
FROM face_results
WHERE has_face = true;
```

#### üîπ ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏û‡∏®‡∏ó‡∏µ‡πà‡∏û‡∏ö

```sql
SELECT gender, COUNT(*) AS count
FROM face_results
WHERE has_face = true
GROUP BY gender;
```

#### üîπ ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤

```sql
SELECT COUNT(*) AS no_face_count
FROM face_results
WHERE has_face = false;
```

---

### ‚úÖ Step 7: Capture ‡∏†‡∏≤‡∏û‡∏™‡πà‡∏á

üì∏ ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏ß‡∏°‡∏™‡∏¥‡πà‡∏á‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡∏†‡∏≤‡∏û‡πÄ‡∏î‡∏µ‡∏¢‡∏ß:

* Glue Job ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå (‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ script ‚Üí ‡πÅ‡∏™‡∏î‡∏á‡πÇ‡∏Ñ‡πâ‡∏î)
* ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå `preprocessed/` ‚Üí ‡πÄ‡∏õ‡∏¥‡∏î‡∏î‡∏π `image_list.json`
* ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå `processed/` ‚Üí ‡πÄ‡∏õ‡∏¥‡∏î‡∏î‡∏π 1 ‡πÑ‡∏ü‡∏•‡πå JSON
* ‡∏ú‡∏•‡∏Ç‡∏≠‡∏á Athena Query:

  * ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
  * ‡πÄ‡∏û‡∏®‡∏ó‡∏µ‡πà‡∏û‡∏ö
  * ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤

---





